{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain and Embeddings\n",
    "This doesn't work yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Fix bug that loads too old of version of sqlite3.\n",
    "# https://docs.trychroma.com/troubleshooting#sqlite\n",
    "# https://gist.github.com/defulmere/8b9695e415a44271061cc8e272f3c300?permalink_comment_id=4691192#gistcomment-4691192\n",
    "# Edit .venv/lib/python3.11/site-packages/chromadb/__init__.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/\n",
    "raw_documents = TextLoader(\"./llama-data/data/apache_logs/1.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    base_url=\"http://g005:11434\",\n",
    "    model=\"llama3.1\",\n",
    ")\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents, embeddings, persist_directory=\"llama-data/embeddings/chroma\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    }
   ],
   "source": [
    "query = \"*\"\n",
    "docs = db.search(query=query, search_type=\"similarity\")\n",
    "\n",
    "data = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 17 lines in this data. I have found the following anomalies:\\n\\n    line 1 and line 2: The user agent string contains \"Windows NT 6.1; WOW64\", which is unusual because Windows NT 6.1 is an old operating system, and WOW64 is a compatibility layer for running 32-bit applications on 64-bit systems.\\n    line 3: The request was made by Googlebot/2.1, but the user agent string claims to be an iPhone running iOS 6.0, which is suspicious because Googlebot is a web crawler and not typically associated with mobile devices.\\n    lines 4-5: Tiny Tiny RSS/1.11 (http://tt-rss.org/) made multiple requests in quick succession, which could indicate that the feed was being scraped or monitored by an automated tool.\\n    line 6: The request was made using HTTP/1.0 instead of a more modern version like HTTP/1.1 or HTTP/2, which is unusual for most web browsers and clients.\\n    lines 7-8: Tiny Tiny RSS/1.11 (http://tt-rss.org/) made multiple requests in quick succession again, similar to lines 4-5.\\n    line 9: The request was made by YandexBot/3.0, but the user agent string claims to be compatible with YandexBot/3.0, which is suspicious because it\\'s not necessary for a legitimate bot to claim compatibility with itself.\\n    line 10: The request was made using HTTP/1.1 instead of a more modern version like HTTP/2, and the user agent string does not identify the client or browser being used, which could indicate that the request was made by an automated tool.\\n    lines 11-12: Tiny Tiny RSS/1.11 (http://tt-rss.org/) made multiple requests in quick succession again, similar to lines 4-5 and 7-8.\\n    line 13: The request was made using HTTP/1.1 instead of a more modern version like HTTP/2, and the user agent string claims to be compatible with Googlebot/2.1, but does not identify the client or browser being used, which could indicate that the request was made by an automated tool.\\n    line 14: The request was made using HTTP/1.0 instead of a more modern version like HTTP/1.1 or HTTP/2, and the user agent string claims to be Firefox/6.0.2, but does not specify the operating system being used, which is unusual because most web browsers identify their operating system.\\n    line 15: The request was made using HTTP/1.1 instead of a more modern version like HTTP/2, and the user agent string does not identify the client or browser being used, which could indicate that the request was made by an automated tool.\\n    lines 16-17: UniversalFeedParser/4.2-pre-314-svn +http://feedparser.org/ made multiple requests in quick succession, similar to Tiny Tiny RSS/1.11 (http://tt-rss.org/) on multiple occasions throughout this data set.\\n\\nThese anomalies suggest that there may be automated tools scraping or monitoring the feeds and pages of semicomplete.com.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OllamaLLM(model=\"llama3.1:70b\")\n",
    "\n",
    "template = \"\"\"\n",
    "Question: Can you find any anomalies in this data?\n",
    "Data: {data}\n",
    "Answer: There are <number of lines> in this data. I have found the following anomalies on:\n",
    "    <line>: <message>\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "model = OllamaLLM(model=\"llama3.1:70b\", base_url=\"http://g005:11434\")\n",
    "chain = prompt | model\n",
    "chain.invoke({\"data\": data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    get_response_synthesizer,\n",
    "    Settings\n",
    ")\n",
    "from llama_index.core.readers.base import BaseReader\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TxtReader(BaseReader):\n",
    "    def load_data(self, file, extra_info=None):\n",
    "        with open(file, \"r\") as f:\n",
    "            text = f.read()\n",
    "        # load_data returns a list of Document objects\n",
    "        return [Document(text=text, extra_info=extra_info or {})]\n",
    "\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[\"llama-data/data/apache_logs/2.txt\"],\n",
    "    file_extractor={\".txt\": TxtReader()},\n",
    ")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"llama3.1:latest\", request_timeout=360.0)\n",
    "Settings.embed_model = OllamaEmbedding(\n",
    "    model_name=\"llama3.1:70b\",\n",
    "    base_url=\"http://g005:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "# build index\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=100\n",
    ")\n",
    "response_synth = get_response_synthesizer()\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synth,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"How many lines are in the loaded data?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
